{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "240654965e339d128a9bbd5be5d7766dbc7de156d15b1c12ed426f21518e5300"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# CCTPY CUDA 程序开发笔记\n",
    "\n",
    "## hello-world\n",
    "\n",
    "先用 hello-world 回顾一下利用纯 C 语言和 pychuda 开发 CUDA 程序"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<pre>\n",
    "#include &lt;stdio.h&gt;\n",
    "\n",
    "// 需要从 CPU 端调用，让 GPU 执行的函数称为内核函数，需要用 __global__ 修饰\n",
    "__global__ void kernel_function(){\n",
    "    printf(\"hello, world! -- from gpu\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"hello, world! -- from cpu\\n\");\n",
    "\n",
    "    // 调用内核函数，使用 <<<>>> 分配块和线程\n",
    "    // 一个块内有多个线程，块内支持内存共享\n",
    "    // 块和线程都是三维结构\n",
    "    // 下面定义了 1*1*1 个块，1*1*1 个线程\n",
    "    kernel_function<<<dim3(1,1,1),dim3(1,1,1)>>>();\n",
    "}\n",
    "</pre>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello, pycuda! -- from python\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n注意：jupyter notebook 中没有打印 GPU 运行信息，可能是监听的 IO 流不对\\n在独立的 py 文件中，能收到 GPU 的打印\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# 内核函数定义\n",
    "mod = SourceModule(\"\"\"\n",
    "    // 需要从 CPU 端调用，让 GPU 执行的函数称为内核函数，需要用 __global__ 修饰\n",
    "    __global__ void kernel_function(){\n",
    "        printf(\"hello, world! -- from gpu\\\\n\");\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "# 获取内核函数\n",
    "kernel_function = mod.get_function(\"kernel_function\")\n",
    "\n",
    "# 调用内核函数\n",
    "# grid 就是块数目定义，block 是块内内存\n",
    "kernel_function(grid=(1,1,1), block=(1,1,1))\n",
    "print(\"hello, pycuda! -- from python\")\n",
    "\n",
    "\"\"\"\n",
    "注意：jupyter notebook 中没有打印 GPU 运行信息，可能是监听的 IO 流不对\n",
    "在独立的 py 文件中，能收到 GPU 的打印\n",
    "\"\"\""
   ]
  },
  {
   "source": [
    "## 块和线程\n",
    "\n",
    "利用 blockIdx.x 可以访问块 x 方向编号\n",
    "\n",
    "利用 threadIdx.x 可以访问线程 x 方向编号\n",
    "\n",
    "GPU 加速粒子跟踪，我的想法是：一个块负责一个束线的一个粒子"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<pre>\n",
    "#include &lt;stdio.h&gt;\n",
    "\n",
    "// 需要从 CPU 端调用，让 GPU 执行的函数称为内核函数，需要用 __global__ 修饰\n",
    "__global__ void kernel_function(){\n",
    "    int bid = blockIdx.x;\n",
    "    int tid = threadIdx.x;\n",
    "    printf(\"bid=%d, tid=%d\\n\",bid,tid);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"hello, world! -- from cpu\\n\");\n",
    "\n",
    "    // 调用内核函数，使用 <<<>>> 分配块和线程\n",
    "    // 一个块内有多个线程，块内支持内存共享\n",
    "    // 块和线程都是三维结构\n",
    "    // 下面定义了 1*1*1 个块，1*1*1 个线程\n",
    "\n",
    "    kernel_function<<<dim3(1,1,1),dim3(1,1,1)>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"---------\\n\");\n",
    "    kernel_function<<<dim3(3,1,1),dim3(1,1,1)>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"---------\\n\");\n",
    "    kernel_function<<<dim3(1,1,1),dim3(3,1,1)>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"---------\\n\");\n",
    "    kernel_function<<<dim3(2,1,1),dim3(2,1,1)>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"---------\\n\");\n",
    "}\n",
    "</pre>\n",
    "\n",
    "**程序输出**\n",
    "\n",
    "<pre>\n",
    "hello, world! -- from cpu\n",
    "bid=0, tid=0\n",
    "---------\n",
    "bid=0, tid=0\n",
    "bid=2, tid=0\n",
    "bid=1, tid=0\n",
    "---------\n",
    "bid=0, tid=0\n",
    "bid=0, tid=1\n",
    "bid=0, tid=2\n",
    "---------\n",
    "bid=0, tid=0\n",
    "bid=0, tid=1\n",
    "bid=1, tid=0\n",
    "bid=1, tid=1\n",
    "---------\n",
    "</pre>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# CUDA 简单运算\n",
    "\n",
    "## 单个数加法\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12.]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "# 内核函数定义\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void add(float *a, float *b,float *ret){\n",
    "        *ret = *a + *b;\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "add = mod.get_function(\"add\")\n",
    "\n",
    "a = np.array([10.0], dtype=np.float32)\n",
    "b = np.array([2], dtype=np.float32)\n",
    "c = np.empty(1, dtype=np.float32)\n",
    "\n",
    "add(drv.In(a), drv.In(b), drv.Out(c), grid=(1,1,1), block=(1,1,1))\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "source": [
    "## 向量加法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.67766273 0.7226967  0.76874584 0.75571066 0.44818532]\n[0.11860567 0.34655762 0.79528314 0.78939086 0.07895472]\n[0.7962684 1.0692544 1.564029  1.5451015 0.52714  ]\n差异：[ 7.4505806e-09  5.9604645e-08  0.0000000e+00  0.0000000e+00\n -2.2351742e-08]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "# 内核函数定义\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void add(float *a, float *b,int *length,float *ret){\n",
    "        int tid = threadIdx.x;\n",
    "        if(tid < *length)\n",
    "            ret[tid] = a[tid] + b[tid];\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "add = mod.get_function(\"add\")\n",
    "\n",
    "length = 5\n",
    "a = np.random.rand(length).astype(np.float32)\n",
    "b = np.random.rand(length).astype(np.float32)\n",
    "c = np.empty_like(a)\n",
    "\n",
    "add(drv.In(a), drv.In(b),drv.In(np.array([length],dtype=np.int32)), drv.Out(c), grid=(1,1,1), block=(length,1,1))\n",
    "\n",
    "print(a,b,c,sep='\\n')\n",
    "print(f\"差异：{c-a-b}\")"
   ]
  },
  {
   "source": [
    "# 规约运算"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}